{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7b3ba6",
   "metadata": {},
   "source": [
    "\n",
    "   # Top 50 Anime Extraction from MyAnimeList API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb13157",
   "metadata": {},
   "source": [
    "#### Install Library necessary for the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84725c43-fec8-4d1c-8062-895b7ab44001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yacbo\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yacbo\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement csv (from versions: none)\n",
      "ERROR: No matching distribution found for csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
      "ERROR: No matching distribution found for json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\yacbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# MySQL Connector\n",
    "%pip install mysql-connector-python\n",
    "\n",
    "# Pandas\n",
    "%pip install pandas\n",
    "\n",
    "# CSV\n",
    "%pip install csv\n",
    "\n",
    "# Json\n",
    "%pip install json\n",
    "\n",
    "# Requests\n",
    "%pip install requests\n",
    "\n",
    "# Python Dotenv\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb8dc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MySQL connector\n",
    "import mysql.connector\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Os\n",
    "import os\n",
    "\n",
    "# Json\n",
    "import json\n",
    "\n",
    "# Requests\n",
    "import requests\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# importing necessary functions from dotenv library\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# loading variables from .env file\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1678d0f",
   "metadata": {},
   "source": [
    "#### Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33470bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to connect to the API\n",
    "api_url = os.getenv(\"MYANIMELIST_URL\")\n",
    "api_key = os.getenv(\"MYANIMELIST_API_KEY\")\n",
    "api_hostname = os.getenv(\"MYANIMELIST_HOSTNAME\")\n",
    "\n",
    "# Variable to connect to MySQL Database\n",
    "db_hostname = os.getenv(\"MYSQL_HOSTNAME\")\n",
    "db_user = os.getenv(\"MYSQL_USERNAME\")\n",
    "db_password = os.getenv(\"MYSQL_PASSWORD\")\n",
    "database = \"TopAnime\"\n",
    "table_name = \"Top50\"\n",
    "\n",
    "# file names\n",
    "json_file = str(datetime.now().year) + \"_\" + str(datetime.now().month) + \"_\" + str(datetime.now().day) + \"_\" + \"TopAnime.json\"\n",
    "csv_file = str(datetime.now().year) + \"_\" + str(datetime.now().month) + \"_\" + str(datetime.now().day) + \"_\" + \"TopAnime.csv\"\n",
    "log_file = str(datetime.now().year) + \"_\" + str(datetime.now().month) + \"_\" + str(datetime.now().day) + \"_\" + \"TopAnime_log.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd7ec6",
   "metadata": {},
   "source": [
    "#### Create the necessary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6abfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, content, mode='a'):\n",
    "    \"\"\"Writes the given log to the log file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file to add the content.\n",
    "        content (str): The content to write to the file.\n",
    "        mode (str, optional): The file opening mode. Defaults to 'a' (append).\n",
    "            Other modes include:\n",
    "            - 'w' (write)\n",
    "            - 'r+' (read and write)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(filename, mode, encoding='utf-8') as file:\n",
    "            file.write(str(datetime.now()) + \": \" + content + \"\\n\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to content to log file.': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590da4b7",
   "metadata": {},
   "source": [
    "#### Connect to the API and retrieve the data from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d5efb6-48a0-418c-a1aa-73deca7db20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define headers\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": api_key,\n",
    "\t\"X-RapidAPI-Host\": api_hostname\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ada270a-f79c-46ae-8111-8730d342353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the GET request to myanimelistAPI\n",
    "write_to_file(log_file, f\"Extracting data from {api_url}\",\"w\")\n",
    "try:\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    write_to_file(log_file, f\"Extracting data from {api_url} successfully\")\n",
    "except:\n",
    "    write_to_file(log_file, f\"Extracting data from {api_url} failed\")\n",
    "    raise SystemExit(\"System stop after error of extracting data from the API\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d74e1cc-7371-4b45-be9f-2979ec1c03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response to JSON\n",
    "data = response.json() \n",
    "\n",
    "# Store the JSON data in a file\n",
    "with open(json_file, \"w\") as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "write_to_file(log_file, f\"Data saved to json file: {json_file}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56422195",
   "metadata": {},
   "source": [
    "Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a77cb4-5e5a-478a-961e-e13f8c653fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(log_file, f\"Starting transformation\")\n",
    "\n",
    "# Convert the data to a panda dataframe\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a387a36a-d2dc-4550-b04d-135f328324ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"picture_url\" and \"members\" Columns\n",
    "df.drop([\"picture_url\",\"members\"],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e90927e-9ebb-4752-872f-327cc71fd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract number of episode from the columns type\n",
    "\n",
    "df[\"Number_Episod\"] = '' # add the columns \"number eps\" to the dataframe df\n",
    "\n",
    "for row in range(len(df)):                          # for each row of the datafrane\n",
    "    start = df.loc[row,\"type\"].find('(') + 1        # find the start position of the number of episode \n",
    "    end = df.loc[row,\"type\"].find(' eps')           # find the end position of the number of episode \n",
    "    try:\n",
    "        nb_ep = int(df.loc[row,\"type\"][start:end])      # extract the number \n",
    "    except ValueError:\n",
    "        nb_ep = None\n",
    "\n",
    "    df.loc[row,\"Number_Episod\"] = nb_ep                # replace the default value inside the columns by the number of episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c37965b-b5df-4663-a25d-d2a3d0024feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the only the type from the columns type\n",
    "\n",
    "for row in range(len(df)):                    # for each row of the datafrane\n",
    "    end = df.loc[row,\"type\"].find(' (')       # find the end position of the number of episode \n",
    "    type_ = df.loc[row,\"type\"][0:end]         # extract the type \n",
    "    df.loc[row,\"type\"] = type_                # replace the value inside the columns by the type extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74dee6f5-eb94-45dc-a77c-fdae78104ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract start date and end date from the columns type\n",
    "\n",
    "for row in range(len(df)):                                           # for each row of the dataframe\n",
    "    start_date = df.loc[row,\"aired_on\"].split(\"-\")[0].strip()        # extract the start date from the \"aired_on\" column\n",
    "    start_date = datetime.strptime(start_date,'%b %Y').date()        # Convert the string to date format\n",
    "    try:\n",
    "        end_date = df.loc[row,\"aired_on\"].split(\"-\")[1].strip()          # extract the end date from the \"aired_on\" column  \n",
    "        end_date = datetime.strptime(end_date,'%b %Y').date()            # Convert the string to date format\n",
    "    except ValueError:\n",
    "        end_date = datetime.now().strftime((\"%Y-%m-%d\"))\n",
    "    df.loc[row,\"Start_date\"] = start_date                            # replace the default value inside the columns by the start date\n",
    "    df.loc[row,\"End_date\"] = end_date                                # replace the default value inside the columns by the end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9470d1e-0343-436b-84ff-0c9f5f27c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns \"aired_on\", rename some columns and set colums \"Rank\" as index\n",
    "df.drop([\"aired_on\"],axis = 1,inplace=True)\n",
    "df.rename(columns={\"rank\": \"Ranking\", \"title\": \"Title\", \"myanimelist_url\": \"Url\", \"myanimelist_id\": \"Id\", \"score\": \"Score\", \"type\": \"Type\" },inplace=True)\n",
    "\n",
    "write_to_file(log_file, f\"Transformation finished successfuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47b4462f-9df2-4612-afc3-dba62a177d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to csv file\n",
    "df.to_csv(csv_file)\n",
    "\n",
    "write_to_file(log_file, f\"Data saved into the csv file: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c0a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(log_file, f\"Connecting to MySQL {database} database\")\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "\n",
    "    cnx = mysql.connector.connect(\n",
    "        host=db_hostname,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        database=database,\n",
    "        port=3306\n",
    "    )\n",
    "\n",
    "    write_to_file(log_file, f\"Connected to {database} database\")\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = cnx.cursor()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f699589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(log_file, f\"Creating table {table_name} into {database} if doesn't exist\")\n",
    "\n",
    "# Create Table Top50 into MYSQL\n",
    "try:\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = cnx.cursor()\n",
    "\n",
    "    # SQL statement to create the table\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Top50 (\n",
    "        Ranking INT UNIQUE NOT NULL PRIMARY KEY,\n",
    "        Title VARCHAR(255),\n",
    "        URL VARCHAR(255),\n",
    "        Id INT,\n",
    "        Score DOUBLE,\n",
    "        Type VARCHAR(255),\n",
    "        Number_Episod INT,\n",
    "        Start_Date DATE,\n",
    "        End_Date DATE)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Execute the SQL statement\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    cnx.commit()\n",
    "\n",
    "    write_to_file(log_file, f\"Table {table_name} created into {database} successfully\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58848f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(log_file,f\"Sending {len(df)} rows to MySQL table '{table_name}'.\")\n",
    "try:\n",
    "    # Create a list of column names from the DataFrame\n",
    "    columns = ', '.join(df.columns)\n",
    "\n",
    "    # Create a placeholders string for the SQL query\n",
    "    placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "\n",
    "    # Create the SQL query\n",
    "    sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Execute the SQL query with the DataFrame values\n",
    "    cursor.executemany(sql, df.values.tolist())\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    cnx.commit()\n",
    "\n",
    "    write_to_file(log_file,f\"Successfully sent {len(df)} rows to MySQL table '{table_name}'.\")\n",
    "except mysql.connector.Error as e:\n",
    "    print(f\"Error sending data to MySQL: {e}\")\n",
    "    write_to_file(log_file,f\"Fail to sent {len(df)} rows to MySQL table '{table_name}'.\")\n",
    "finally:\n",
    "    # Close the database cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if cnx:\n",
    "        cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dadd8687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title, Url, Id, Ranking, Score, Type, Number_Episod, Start_date, End_date'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ', '.join(df.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54239680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
