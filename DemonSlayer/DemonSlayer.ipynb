{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e3e9bd",
   "metadata": {},
   "source": [
    "<a align=\"center\">\n",
    "    <img src=\"DemonSlayer.jpg\" width=\"500\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0cc98b",
   "metadata": {},
   "source": [
    "<font color='green' size= 6 ><b>Install the following library if not already installed</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41094e26",
   "metadata": {},
   "source": [
    "##### Pandas: %pip install pandas\n",
    "\n",
    "##### Python Dotenv: %pip install python-dotenv\n",
    "\n",
    "##### Requests: %pip install requests\n",
    "\n",
    "##### Beautiful soup: %pip install bs4\n",
    "\n",
    "##### MySQL Connector: %pip install mysql-connector-python\n",
    "\n",
    "##### Selenium: %pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0518d",
   "metadata": {},
   "source": [
    "<font color='green' size= 6 ><b>Import Library necessary for the Project and define the variables</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acdfd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing os ans sys modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Navigate to project directory to import modules\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Importing function create from Manga_function.py\n",
    "from Functions.Manga_function import write_to_file, create_soup, extract_date, extract_episod, extract_link, extract_title \n",
    "\n",
    "# MySQL connector\n",
    "import mysql.connector\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# importing os module for environment variables\n",
    "import os\n",
    "\n",
    "# importing necessary functions from dotenv library\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# loading variables from .env file\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cd2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables\n",
    "\n",
    "host = os.getenv(\"MYSQL_HOSTNAME\")\n",
    "user = os.getenv(\"MYSQL_USERNAME\")\n",
    "password = os.getenv(\"MYSQL_PASSWORD\")\n",
    "database = \"manga\"\n",
    "table_name = \"DemonSlayer\"\n",
    "manga_name = \"Demon Slayer\"\n",
    "csv_file = \"C:/Users/yacbo/Documents/Data_Engineer/Training/Manga_Project/DemonSlayer/DemonSlayer.csv\"\n",
    "log_file = \"C:/Users/yacbo/Documents/Data_Engineer/Training/Manga_Project/DemonSlayer/DemonSlayer.txt\"\n",
    "url = os.getenv(\"URL\")\n",
    "number_tot_ep = 63"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a60f9",
   "metadata": {},
   "source": [
    "<font color='green' size= 6 ><b>Run \"Manga_init.ipynb\"</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1702dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:\\Users\\yacbo\\Documents\\Data_Engineer\\Training\\Manga_Project\\Manga_init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a7bae",
   "metadata": {},
   "source": [
    "<font color='green' size= 6 ><b>Extract and Transform the data</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac13ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_ep_to_extract == 0 :\n",
    "    write_to_file(log_file, f\"Program stopped because there is no data to extract\")\n",
    "    raise SystemExit(\"System stop because there is no episod to extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8682d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the first link to extract\n",
    "if number_ep_database == 0: # if no episod in database take the episod 1 link\n",
    "    link  = url\n",
    "else: # if there is some episod in database extract the link from the last episod extracted\n",
    "    # Extract link of the last episod in database\n",
    "    try:\n",
    "            # Execute a query\n",
    "        cursor.execute(f\"SELECT link from {table_name} order by Episod desc limit 1\")\n",
    "        link_database = cursor.fetchall()\n",
    "        link_database = str(link_database[0][0])\n",
    "    except mysql.connector.Error as err:\n",
    "        write_to_file(log_file, f\"There is an error : {err}\")\n",
    "        # Close the database cursor and connection\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if cnx:\n",
    "            cnx.close()\n",
    "\n",
    "    # Create a beaufiful soup from this link and extract the link of the following episod       \n",
    "    soup = create_soup(link_database)\n",
    "    link = soup.find_all('a', class_='ipc-icon-button sc-3f4e3993-3 iasCTO ipc-icon-button--baseAlt ipc-icon-button--onBase')[1].attrs['href']\n",
    "    link = extract_link(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "047b47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists\n",
    "season_list = []\n",
    "episod_season_list = []\n",
    "episod_list= []\n",
    "title_list = []\n",
    "rating_list = []\n",
    "day_list= []\n",
    "month_list= []\n",
    "year_list = []\n",
    "link_list = []\n",
    "\n",
    "link_list.append(link)\n",
    "\n",
    "# Extract data for each episod\n",
    "for i in range(number_ep_to_extract):\n",
    "\n",
    "    try:\n",
    "\n",
    "        write_to_file(log_file, f\"Extracting episod {number_ep_database+1+i} from {link}\")\n",
    "        soup = create_soup(link)\n",
    "        \n",
    "        # Season and Episod\n",
    "        ep = soup.find('div', class_=\"sc-3f4e3993-0 fYpskP\").text\n",
    "        season,episod_season = extract_episod(ep)\n",
    "        season_list.append(season)\n",
    "        episod_season_list.append(episod_season)\n",
    "\n",
    "        # Title\n",
    "        title = extract_title(soup.find('span', class_=\"hero__primary-text\").text)\n",
    "        title_list.append(title)\n",
    "\n",
    "        # Date\n",
    "        date = soup.find_all('li', class_=\"ipc-inline-list__item\")\n",
    "        day,month,year = extract_date(date)\n",
    "        day_list.append(day)\n",
    "        month_list.append(month)\n",
    "        year_list.append(year)\n",
    "\n",
    "        #Rating\n",
    "        rate = soup.find('span', class_=\"sc-c4ffe080-1 iQZtLP\").text.replace(\",\",\".\")\n",
    "        rating_list.append(float(rate))\n",
    "\n",
    "        write_to_file(log_file, f\"Extracted correctly the following episod: Saison: {season} | Episode: {episod_season} | Title: {title} | Rate: {rate}\")\n",
    "\n",
    "        #Link \n",
    "\n",
    "        if i == 0 and number_ep_database == 0: \n",
    "            link = soup.find('a', class_='ipc-icon-button sc-3f4e3993-3 iasCTO ipc-icon-button--baseAlt ipc-icon-button--onBase').attrs['href']\n",
    "        else:\n",
    "            link = soup.find_all('a', class_='ipc-icon-button sc-3f4e3993-3 iasCTO ipc-icon-button--baseAlt ipc-icon-button--onBase')[1].attrs['href']\n",
    "\n",
    "        if i < number_ep_to_extract - 1:        \n",
    "            link = extract_link(link)\n",
    "            link_list.append(link)\n",
    "\n",
    "        i = i+1   \n",
    "\n",
    "    except IndexError:\n",
    "        pass\n",
    "        \n",
    "    except WebDriverException: \n",
    "        write_to_file(log_file, f\"Extracting episod {number_ep_database+1+i} from {link} failed\")\n",
    "\n",
    "number_ep_extracted = i \n",
    "\n",
    "episod_list = list(range(number_ep_database + 1, number_ep_database + 1 + number_ep_extracted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffa943",
   "metadata": {},
   "source": [
    "<font color='green' size= 6 ><b>Load the data</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c4ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of the data\n",
    "data = {\"Episod\":episod_list,\"Season\":season_list,\"Episod_season\":episod_season_list, \"Title\":title_list, \"Day\":day_list, \"Month\":month_list, \"Year\":year_list, \"Rate\":rating_list, \"link\":link_list}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if all the data have been successfully extracted\n",
    "if df.shape[0] == number_ep_to_extract:\n",
    "    write_to_file(log_file,f\"Extracting {number_ep_to_extract} episod successfuly\")\n",
    "else:\n",
    "    write_to_file(log_file,f\"Extraction failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f6f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a csv file\n",
    "df.to_csv(csv_file,index=False,mode= \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f22666b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into MySQL database\n",
    "\n",
    "write_to_file(log_file,f\"Sending {len(df)} rows to MySQL table '{table_name}'.\")\n",
    "try:\n",
    "    # Create a list of column names from the DataFrame\n",
    "    columns = ', '.join(df.columns)\n",
    "\n",
    "    # Create a placeholders string for the SQL query\n",
    "    placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "\n",
    "    # Create the SQL query\n",
    "    sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Execute the SQL query with the DataFrame values\n",
    "    cursor.executemany(sql, df.values.tolist())\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    cnx.commit()\n",
    "\n",
    "    write_to_file(log_file,f\"Successfully sent {len(df)} rows to MySQL table '{table_name}'.\")\n",
    "except mysql.connector.Error as e:\n",
    "    print(f\"Error sending data to MySQL: {e}\")\n",
    "finally:\n",
    "    # Close the database cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if cnx:\n",
    "        cnx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
